/*
 * // Copyright (c) Radzivon Bartoshyk 7/2025. All rights reserved.
 * //
 * // Redistribution and use in source and binary forms, with or without modification,
 * // are permitted provided that the following conditions are met:
 * //
 * // 1.  Redistributions of source code must retain the above copyright notice, this
 * // list of conditions and the following disclaimer.
 * //
 * // 2.  Redistributions in binary form must reproduce the above copyright notice,
 * // this list of conditions and the following disclaimer in the documentation
 * // and/or other materials provided with the distribution.
 * //
 * // 3.  Neither the name of the copyright holder nor the names of its
 * // contributors may be used to endorse or promote products derived from
 * // this software without specific prior written permission.
 * //
 * // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * // AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * // IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * // DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 * // FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * // DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * // SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * // CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * // OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
use crate::double_double::DoubleDouble;
use crate::j0_coeffs::J0_COEFFS;
use crate::j0f_coeffs::{J0_ZEROS, J0_ZEROS_VALUE};
use crate::polyeval::{f_polyeval8, f_polyeval12};
use crate::sin_helper::cos_dd_small;
use crate::sincos_reduce::{AngleReduced, rem2pi_any};

/// Bessel of the first kind J0
///
/// Max ULP 0.5
pub fn f_j0(x: f64) -> f64 {
    let x_abs = x.to_bits() & 0x7fff_ffff_ffff_ffff;

    if !x.is_normal() {
        if f64::from_bits(x_abs) == 0. {
            // J0 value at 0
            return f64::from_bits(0x3ff0000000000000);
        }
        if x.is_infinite() {
            return 0.;
        }
        if x.is_nan() {
            return x + x;
        }
    }

    if f64::from_bits(x_abs) <= 74.8 {
        if f64::from_bits(x_abs) <= 0.25 {
            return j0_maclaurin_series(x);
        }
        return j0_small_argument_path(x);
    }

    // Exceptions
    if x_abs == 0x571a31ffe2ff7e9f {
        return f64::from_bits(0xb2e58532f95056ff);
    } else if x_abs == 0x7f2109fb0b442158u64 {
        return f64::from_bits(0x9fdcdbc94d3753ee);
    }

    j0_asympt(x)
}

/**
Generated by SageMath:
```python
mp.prec = 180
def print_expansion_at_0():
    print(f"const J0_MACLAURIN_SERIES: [(u64, u64); 12] = [")
    from mpmath import mp, j0, taylor
    poly = taylor(lambda val: j0(val), 0, 24)
    # print(poly)
    real_i = 0
    for i in range(0, 24, 2):
        print_double_double("", DD(poly[i]))
        real_i = real_i + 1
    print("];")
    print(poly)

print_expansion_at_0()
```
**/
#[inline]
pub(crate) fn j0_maclaurin_series(x: f64) -> f64 {
    const C: [(u64, u64); 12] = [
        (0x0000000000000000, 0x3ff0000000000000),
        (0x0000000000000000, 0xbfd0000000000000),
        (0x0000000000000000, 0x3f90000000000000),
        (0xbbdc71c71c71c71c, 0xbf3c71c71c71c71c),
        (0x3b7c71c71c71c71c, 0x3edc71c71c71c71c),
        (0xbab23456789abcdf, 0xbe723456789abcdf),
        (0xba8b6edec0692e65, 0x3e002e85c0898b71),
        (0x3a2604db055bd075, 0xbd8522a43f65486a),
        (0xb9a604db055bd075, 0x3d0522a43f65486a),
        (0x3928824198c6f6e1, 0xbc80b313289be0b9),
        (0xb869b0b430eb27b8, 0x3bf5601885e63e5d),
        (0x380ee6b4638f3a25, 0xbb669ca9cf3b7f54),
    ];

    let dx2 = DoubleDouble::from_exact_mult(x, x);

    let p = f_polyeval12(
        dx2,
        DoubleDouble::from_bit_pair(C[0]),
        DoubleDouble::from_bit_pair(C[1]),
        DoubleDouble::from_bit_pair(C[2]),
        DoubleDouble::from_bit_pair(C[3]),
        DoubleDouble::from_bit_pair(C[4]),
        DoubleDouble::from_bit_pair(C[5]),
        DoubleDouble::from_bit_pair(C[6]),
        DoubleDouble::from_bit_pair(C[7]),
        DoubleDouble::from_bit_pair(C[8]),
        DoubleDouble::from_bit_pair(C[9]),
        DoubleDouble::from_bit_pair(C[10]),
        DoubleDouble::from_bit_pair(C[11]),
    );
    let z = DoubleDouble::from_exact_add(p.hi, p.lo);
    z.to_f64()
}

/// This method on small range searches for nearest zero or extremum.
/// Then picks stored series expansion at the point end evaluates the poly at the point.
#[inline]
pub(crate) fn j0_small_argument_path(x: f64) -> f64 {
    let x_abs = f64::from_bits(x.to_bits() & 0x7fff_ffff_ffff_ffff);

    // let avg_step = 74.6145 / 47.0;
    // let inv_step = 1.0 / avg_step;

    const INV_STEP: f64 = 0.6299043751549631;

    let fx = x_abs * INV_STEP;
    const J0_ZEROS_COUNT: f64 = (J0_ZEROS.len() - 1) as f64;
    let idx0 = fx.min(J0_ZEROS_COUNT) as usize;
    let idx1 = fx.ceil().min(J0_ZEROS_COUNT) as usize;

    let found_zero0 = DoubleDouble::from_bit_pair(J0_ZEROS[idx0]);
    let found_zero1 = DoubleDouble::from_bit_pair(J0_ZEROS[idx1]);

    let dist0 = (found_zero0.hi - x_abs).abs();
    let dist1 = (found_zero1.hi - x_abs).abs();

    let (found_zero, idx, dist) = if dist0 < dist1 {
        (found_zero0, idx0, dist0)
    } else {
        (found_zero1, idx1, dist1)
    };

    if idx == 0 {
        return j0_maclaurin_series(x);
    }

    let j1c = &J0_COEFFS[idx - 1];
    let c = j1c.c;

    let r = DoubleDouble::full_add_f64(DoubleDouble::new(-found_zero.lo, -found_zero.hi), x_abs);

    // We hit exact zero, value, better to return it directly
    if dist == 0. {
        return f64::from_bits(J0_ZEROS_VALUE[idx]);
    }

    let p = f_polyeval8(
        r.to_f64(),
        f64::from_bits(c[0]),
        f64::from_bits(c[1]),
        f64::from_bits(c[2]),
        f64::from_bits(c[3]),
        f64::from_bits(c[4]),
        f64::from_bits(c[5]),
        f64::from_bits(c[6]),
        f64::from_bits(c[7]),
    );

    let mut p_e = DoubleDouble::mul_f64_add(r, p, DoubleDouble::from_bit_pair(j1c.a15));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a14));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a13));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a12));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a11));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a10));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a9));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a8));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a7));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a6));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a5));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a4));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a3));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a2));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a1));
    p_e = DoubleDouble::mul_add(p_e, r, DoubleDouble::from_bit_pair(j1c.a0));

    let sums = DoubleDouble::from_full_exact_add(p_e.hi, p_e.lo);
    sums.to_f64()
}

/**
Note expansion generation below: this is negative series expressed in Sage as positive,
so before any real evaluation `x=1/x` should be applied.

Generated by SageMath:
```python
def binomial_like(n, m):
    prod = QQ(1)
    z = QQ(4)*(n**2)
    for k in range(1,m + 1):
        prod *= (z - (2*k - 1)**2)
    return prod / (QQ(2)**(2*m) * (ZZ(m).factorial()))

R = LaurentSeriesRing(RealField(300), 'x',default_prec=300)
x = R.gen()

def Pn_asymptotic(n, y, terms=10):
    # now y = 1/x
    return sum( (-1)**m * binomial_like(n, 2*m) / (QQ(2)**(2*m)) * y**(QQ(2)*m) for m in range(terms) )

def Qn_asymptotic(n, y, terms=10):
    return sum( (-1)**m * binomial_like(n, 2*m + 1) / (QQ(2)**(2*m + 1)) * y**(QQ(2)*m + 1) for m in range(terms) )

P = Pn_asymptotic(0, x, 50)
Q = Qn_asymptotic(0, x, 50)

R_series = (-Q/P)

# alpha is atan(R_series) so we're doing Taylor series atan expansion on R_series

arctan_series_Z = sum([QQ(-1)**k * x**(QQ(2)*k+1) / RealField(700)(RealField(700)(2)*k+1) for k in range(25)])
alpha_series = arctan_series_Z(R_series)

# see the series
print(alpha_series)
```
**/
#[inline]
pub(crate) fn j0_asympt_alpha(recip: DoubleDouble) -> DoubleDouble {
    const C: [(u64, u64); 12] = [
        (0x0000000000000000, 0x3fc0000000000000),
        (0x3c55555555555555, 0xbfb0aaaaaaaaaaab),
        (0x3c5999999999999a, 0x3fcad33333333333),
        (0xbc92492492492492, 0xbffa358492492492),
        (0xbcbc71c71c71c71c, 0x403779a1f8e38e39),
        (0xbd0745d1745d1746, 0xc080bd1fc8b1745d),
        (0xbd7d89d89d89d89e, 0x40d16b51e66c789e),
        (0x3dc5555555555555, 0xc128ecc3af33ab37),
        (0x3e2143c3c3c3c3c4, 0x418779dae2b8512f),
        (0x3df41e50d79435e5, 0xc1ec296336955c7f),
        (0x3ef6dcbaf0618618, 0x4254f5ee683b6432),
        (0x3f503a3102cc7a6f, 0xc2c2f51eced6693f),
    ];

    // Doing (1/x)*(1/x) instead (1/(x*x)) to avoid spurious overflow/underflow
    let x2 = DoubleDouble::quick_mult(recip, recip);

    let mut p = DoubleDouble::mul_add(
        x2,
        DoubleDouble::from_bit_pair(C[11]),
        DoubleDouble::from_bit_pair(C[10]),
    );

    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[9]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[8]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[7]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[6]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[5]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[4]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[3]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[2]));
    p = DoubleDouble::mul_add(x2, p, DoubleDouble::from_bit_pair(C[1]));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[0].1));

    let z = DoubleDouble::quick_mult(p, recip);

    DoubleDouble::from_exact_add(z.hi, z.lo)
}

/**
Beta series

Generated by SageMath:
```python
#generate b series
def binomial_like(n, m):
    prod = QQ(1)
    z = QQ(4)*(n**2)
    for k in range(1,m + 1):
        prod *= (z - (2*k - 1)**2)
    return prod / (QQ(2)**(2*m) * (ZZ(m).factorial()))

R = LaurentSeriesRing(RealField(300), 'x',default_prec=300)
x = R.gen()

def Pn_asymptotic(n, y, terms=10):
    # now y = 1/x
    return sum( (-1)**m * binomial_like(n, 2*m) / (QQ(2)**(2*m)) * y**(QQ(2)*m) for m in range(terms) )

def Qn_asymptotic(n, y, terms=10):
    return sum( (-1)**m * binomial_like(n, 2*m + 1) / (QQ(2)**(2*m + 1)) * y**(QQ(2)*m + 1) for m in range(terms) )

P = Pn_asymptotic(0, x, 50)
Q = Qn_asymptotic(0, x, 50)

def sqrt_series(s):
    val = S.valuation()
    lc = S[val]  # Leading coefficient
    b = lc.sqrt() * x**(val // 2)

    for _ in range(5):
        b = (b + S / b) / 2
        b = b
    return b

S = (P**2 + Q**2).truncate(50)

b_series = sqrt_series(S).truncate(30)
#see the series
print(b_series)
```
**/
#[inline]
pub(crate) fn j0_asympt_beta(recip: DoubleDouble) -> DoubleDouble {
    const C: [(u64, u64); 10] = [
        (0x0000000000000000, 0x3ff0000000000000),
        (0x0000000000000000, 0xbfb0000000000000),
        (0x0000000000000000, 0x3fba800000000000),
        (0x0000000000000000, 0xbfe15f0000000000),
        (0x0000000000000000, 0x4017651180000000),
        (0x0000000000000000, 0xc05ab8c13b800000),
        (0x0000000000000000, 0x40a730492f262000),
        (0x0000000000000000, 0xc0fc73a7acd696f0),
        (0xbdf3a00000000000, 0x41577458dd9fce68),
        (0xbe4ba6b000000000, 0xc1b903ab9b27e18f),
    ];

    // Doing (1/x)*(1/x) instead (1/(x*x)) to avoid spurious overflow/underflow
    let x2 = DoubleDouble::quick_mult(recip, recip);

    let mut p = DoubleDouble::mul_add(
        x2,
        DoubleDouble::from_bit_pair(C[9]),
        DoubleDouble::from_bit_pair(C[8]),
    );

    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[7].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[6].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[5].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[4].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[3].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[2].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[1].1));
    p = DoubleDouble::mul_add_f64(x2, p, f64::from_bits(C[0].1));
    p
}

/*
   Evaluates:
   J1 = sqrt(2/(PI*x)) * beta(x) * cos(x - PI/4 - alpha(x))
*/
pub(crate) fn j0_asympt(x: f64) -> f64 {
    let x = x.abs();

    const SQRT_2_OVER_PI: DoubleDouble = DoubleDouble::new(
        f64::from_bits(0xbc8cbc0d30ebfd15),
        f64::from_bits(0x3fe9884533d43651),
    );
    const MPI_OVER_4: DoubleDouble = DoubleDouble::new(
        f64::from_bits(0xbc81a62633145c07),
        f64::from_bits(0xbfe921fb54442d18),
    );

    let recip = if x.to_bits() > 0x7fd000000000000u64 {
        DoubleDouble::quick_mult_f64(DoubleDouble::from_exact_safe_div(4.0, x), 0.25)
    } else {
        DoubleDouble::from_recip(x)
    };

    let alpha = j0_asympt_alpha(recip);
    let beta = j0_asympt_beta(recip);

    let AngleReduced { angle } = rem2pi_any(x);

    // Without full subtraction cancellation happens sometimes
    let x0pi34 = DoubleDouble::dd_sub(MPI_OVER_4, alpha);
    let r0 = DoubleDouble::dd_add(angle, x0pi34);

    let m_cos = cos_dd_small(r0);
    let z0 = DoubleDouble::quick_mult(beta, m_cos);
    let r_sqrt = DoubleDouble::from_rsqrt(x);
    let scale = DoubleDouble::quick_mult(SQRT_2_OVER_PI, r_sqrt);
    let p = DoubleDouble::quick_mult(scale, z0);
    let norm = DoubleDouble::from_full_exact_add(p.hi, p.lo);
    norm.to_f64()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_j0() {
        assert_eq!(f_j0(-2.3369499004222215E+304), -3.3630754230844632e-155);
        assert_eq!(
            f_j0(f64::from_bits(0xd71a31ffe2ff7e9f)),
            f64::from_bits(0xb2e58532f95056ff)
        );
        assert_eq!(f_j0(6.1795701510782757E+307), 6.075192922402001e-155);
        assert_eq!(f_j0(6.1795701510782757E+301), 4.118334155030934e-152);
        assert_eq!(f_j0(6.1795701510782757E+157), 9.5371668900364e-80);
        assert_eq!(f_j0(79.), -0.08501719554953485);
        // Without FMA 2.703816901253004e-16
        #[cfg(any(
            all(target_arch = "x86_64", target_feature = "fma"),
            target_arch = "aarch64"
        ))]
        assert_eq!(f_j0(93.463718781944774171190), 2.7038169012530046e-16);
        assert_eq!(f_j0(99.746819858680596470279979), -8.419106281522749e-17);
        assert_eq!(f_j0(f64::INFINITY), 0.);
        assert_eq!(f_j0(f64::NEG_INFINITY), 0.);
        assert!(f_j0(f64::NAN).is_nan());
    }
}
